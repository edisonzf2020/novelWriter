# Story 2.3: 智能的API端点能力检测

## Status
Approved

## Story
**As a** 开发者,
**I want** AI Provider能够自动检测所连接的API端点支持哪些高级功能,
**so that** 系统能够自动选择最优的协议路径，最大化功能可用性。

## Acceptance Criteria
1. `OpenAICompatibleProvider` 在首次连接时进行懒检测。
2. 能自动判断并优先使用 `POST /v1/responses` 接口，否则回退到 `POST /v1/chat/completions`。
3. 检测结果在会话级别缓存，并记入调试日志。

## Tasks / Subtasks
- [ ] 创建 `OpenAICompatibleProvider` 基础类架构 (AC: 1,2,3)
  - [ ] 设计Provider基础接口，支持lazy initialization和capability detection
  - [ ] 实现基础的HTTP客户端，使用httpx作为默认通道
  - [ ] 添加配置参数：base_url, api_key, model, timeout等
- [ ] 实现端点能力检测机制 (AC: 1,2)
  - [ ] 创建 `_detect_capabilities()` 方法，检测API端点支持的功能
  - [ ] 实现 `/v1/responses` 端点探测逻辑，测试是否支持新接口
  - [ ] 实现回退机制：失败时自动降级到 `/v1/chat/completions`
  - [ ] 检测流式输出(SSE)、工具调用、最大tokens等高级特性支持
- [ ] 实现会话级别缓存机制 (AC: 3)
  - [ ] 设计capability cache结构，存储检测到的端点能力
  - [ ] 实现缓存生命周期管理，避免重复检测
  - [ ] 添加手动刷新检测的接口，用于配置变更后的重新检测
- [ ] 集成调试日志和可观测性 (AC: 3)
  - [ ] 记录详细的端点检测过程和结果
  - [ ] 记录回退决策和性能影响
  - [ ] 提供检测状态的查询接口，便于故障排查
- [ ] 创建Provider工厂和管理机制
  - [ ] 实现Provider实例的创建和配置管理
  - [ ] 集成到现有的AI配置系统中
  - [ ] 支持多Provider类型的扩展架构

## Dev Notes

### Previous Story Insights
- Story 2.2 实现了上下文选择和会话记忆，本Story专注于底层Provider能力，为后续的AI交互提供可靠的协议基础。[Source: docs/stories/2.2.flexible-context-selection.md]
- Story 2.1 中的事务化写入操作将依赖于本Story提供的稳定Provider连接。[Source: docs/stories/2.1.nwaiapi-write-ops.md]

### Provider架构设计
- 遵循统一接口：`generate(messages, tools=None, stream=False, timeout=...)`，支持多种Provider类型的无缝切换。[Source: docs/AI/AI_ASSISTANT_PLAN.md#6-agent-运行时]
- 使用httpx作为默认HTTP客户端，提供更好的兼容性覆盖，同时预留SDK路径的集成可能。[Source: docs/AI/AI_ASSISTANT_PLAN.md#61-p0-provider-选择openai-api-兼容栈]
- 支持base_url配置，实现对官方OpenAI和兼容服务的无缝支持。[Source: docs/AI/AI_ASSISTANT_PLAN.md#63-openai-兼容配置项p0]

### 端点检测策略
- 首选 `/v1/responses` 端点（新接口），支持工具调用和流式输出的完整特性。[Source: docs/AI/AI_ASSISTANT_PLAN.md#62-端点能力检测p1]
- 回退到 `/v1/chat/completions`（标准接口），保证基础对话功能的兼容性。[Source: docs/AI/AI_ASSISTANT_PLAN.md#62-端点能力检测p1]
- 懒检测策略：仅在首次请求或显式刷新时进行能力探测，减少不必要的网络开销。[Source: docs/AI/AI_ASSISTANT_PLAN.md#62-端点能力检测p1]

### 缓存和可观测性
- Provider会话级别缓存检测结果，避免重复探测影响性能。[Source: docs/AI/AI_ASSISTANT_PLAN.md#62-端点能力检测p1]
- 所有检测过程写入调试日志，包含端点响应时间、支持特性列表、回退决策等关键信息。[Source: docs/AI/AI_ASSISTANT_PLAN.md#62-端点能力检测p1]
- 提供检测状态查询，便于开发者和用户诊断连接问题。

### 技术实现细节
- 依赖管理：核心功能仅依赖httpx和pydantic，OpenAI SDK作为可选依赖。[Source: docs/AI/AI_ASSISTANT_PLAN.md#72-可选依赖pyprojecttoml]
- 错误处理：网络超时、认证失败、端点不支持等情况的优雅降级。[Source: novelwriter/ai/errors.py]
- 配置集成：与现有AIConfig系统对接，支持provider、model、base_url等参数。[Source: novelwriter/ai/config.py]

### 文件位置
- Provider基类：`novelwriter/ai/providers/__init__.py` (新建)
- OpenAI兼容Provider：`novelwriter/ai/providers/openai_compatible.py` (新建)
- Provider工厂：`novelwriter/ai/providers/factory.py` (新建) 
- 测试文件：`tests/test_ai/test_providers.py` (新建)

### Testing
- 模拟不同端点的响应情况（支持/不支持各种特性）
- 测试网络异常和超时场景的处理
- 验证缓存机制的正确性和生命周期
- 测试配置变更后的重新检测逻辑

## Testing
- `pytest tests/test_ai/test_providers.py`
- `pytest tests/test_ai/test_api.py` (集成测试)

## Change Log
| Date | Version | Description | Author |
| --- | --- | --- | --- |
| 2025-09-17 | 0.1 | Initial draft | Bob (Scrum Master) |

## Dev Agent Record
### Agent Model Used
_TBD_

### Debug Log References
_TBD_

### Completion Notes List
_TBD_

### File List
_TBD_

## QA Results
_TBD_