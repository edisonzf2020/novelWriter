# Story 1.8: 性能监控和指标收集

## Status
Approved

## Story
**As a** 运维工程师，
**I want** 实时监控系统性能和工具调用指标，
**so that** 就能够及时发现问题并进行针对性优化。

## Acceptance Criteria
1. 实现`PerformanceMonitor`类，收集延迟、成功率、并发数
2. 建立实时性能统计（P95、P99、平均值）计算
3. 实现性能基准对比和趋势分析
4. 建立性能告警机制，超阈值自动通知
5. 集成性能监控到状态栏显示

## Tasks / Subtasks

- [ ] Task 1: PerformanceMonitor核心类实现 (AC: 1)
  - [ ] 设计性能指标数据模型（延迟、成功率、并发数、吞吐量）
  - [ ] 实现指标收集装饰器，自动捕获方法执行时间和状态
  - [ ] 创建线程安全的指标聚合器，支持高并发场景
  - [ ] 建立时间窗口滑动机制，维护近期性能数据
  - [ ] 实现指标持久化和历史数据管理

- [ ] Task 2: 实时性能统计计算 (AC: 2)
  - [ ] 实现P95、P99、平均值、最大值、最小值统计算法
  - [ ] 创建滑动窗口统计计算器，支持1分钟、5分钟、15分钟窗口
  - [ ] 建立分位数近似算法（t-digest），优化内存使用
  - [ ] 实现统计数据的原子更新机制，确保数据一致性
  - [ ] 添加性能热点识别和分析功能

- [ ] Task 3: 性能基准对比和趋势分析 (AC: 3)
  - [ ] 建立基准性能数据库，记录正常运行期间的性能基准
  - [ ] 实现趋势分析算法，检测性能退化和改善趋势
  - [ ] 创建性能对比报告生成器，支持时间段对比
  - [ ] 建立异常检测机制，识别性能波动和异常模式
  - [ ] 实现性能回归检测，在版本更新后自动验证

- [ ] Task 4: 性能告警机制 (AC: 4)
  - [ ] 设计可配置的性能阈值管理系统
  - [ ] 实现智能告警引擎，避免告警风暴和重复通知
  - [ ] 创建多级告警系统（INFO、WARN、ERROR、CRITICAL）
  - [ ] 建立告警抑制和延迟机制，减少误报
  - [ ] 集成邮件、桌面通知等多种告警渠道

- [ ] Task 5: 状态栏性能监控集成 (AC: 5)
  - [ ] 扩展主窗口状态栏，添加性能指标显示区域
  - [ ] 实现实时性能数据的UI更新机制
  - [ ] 创建性能监控弹窗详情界面，支持历史查看
  - [ ] 建立性能状态颜色指示器（绿、黄、红）
  - [ ] 添加性能图表和可视化组件

## Dev Notes

### 技术架构要求
基于架构文档，性能监控模块必须集成到统一API中间层：

**集成位置**: `novelwriter/api/base/performance.py`
- 作为统一API的核心组件，监控所有通过API的调用
- 与SecurityController并行工作，不影响权限控制流程
- 集成到NovelWriterAPI中，通过依赖注入提供给其他组件

**数据收集策略**:
- 装饰器模式：自动包装API方法，透明收集性能数据
- 异步收集：使用独立线程处理指标计算，不影响主流程
- 内存优化：使用滑动窗口和采样算法，控制内存占用

### 与现有系统集成
**AI模块集成**:
- 监控`ai/ai_core.py`中的AI服务调用性能
- 收集AI provider响应时间和成功率指标
- 集成到现有AI配置系统，支持性能阈值配置

**MCP工具监控**:
- 区分本地工具和外部MCP工具的性能指标
- 监控工具调用链路，识别性能瓶颈
- 集成熔断器状态，关联故障恢复机制

**UI集成要求**:
- 使用PyQt6现有主题系统，支持浅色/深色主题
- 集成到现有状态栏布局，不影响其他状态显示
- 遵循现有国际化机制，支持多语言界面

### 性能要求
**实时性约束**:
- 指标收集开销 < 0.5%：不能影响正常工具调用性能
- UI更新频率：每秒更新一次，不影响编辑体验
- 内存限制：性能数据占用不超过总内存的2%

**数据精度要求**:
- 时间精度：微秒级别（使用time.perf_counter()）
- 统计精度：P95/P99误差 < 1%
- 数据保留期：内存中保留1小时，历史数据持久化

### 依赖注入模式
按照架构设计，所有组件通过构造函数接收依赖：

```python
class PerformanceMonitor:
    def __init__(self, config: "MCPConfig", logger: "Logger"):
        self._config = config
        self._logger = logger
        # 不直接访问core，通过API统一访问

class NovelWriterAPI:
    def __init__(self, project: "NWProject", perf_monitor: "PerformanceMonitor"):
        self._project = project
        self._perf_monitor = perf_monitor
        # 通过装饰器自动监控所有API方法
```

### Testing
**测试框架**: pytest，使用现有测试基础设施
**测试文件位置**: `tests/test_api/test_performance_monitor.py`

**测试类别**:
1. **单元测试**: 
   - 指标收集准确性测试
   - 统计算法正确性验证
   - 线程安全性测试

2. **性能测试**:
   - 指标收集开销基准测试（< 0.5%）
   - 高并发场景压力测试
   - 内存使用量测试

3. **集成测试**:
   - 与统一API集成测试
   - UI组件集成测试
   - 告警机制端到端测试

**测试要求**:
- 使用虚拟环境：`source writer/bin/activate`
- 测试命令：`pytest tests/test_api/test_performance_monitor.py -v`
- 覆盖率要求：≥ 90%

**模拟测试**:
- 使用mock模拟高延迟场景
- 模拟系统负载变化
- 验证告警触发的准确性

### 关键设计决策
1. **统计算法选择**: t-digest算法用于分位数计算，平衡精度和性能
2. **存储策略**: 内存 + 可选持久化，支持重启后数据恢复
3. **告警策略**: 智能抑制机制，避免告警风暴
4. **UI更新策略**: 异步更新，不阻塞主线程
5. **配置管理**: 集成现有CONFIG系统，支持热更新

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-25 | v1.0 | Initial story creation based on PRD v3.0 Epic 1 Story 1.8, following create-next-story task flow and architecture alignment | BMAD SM |